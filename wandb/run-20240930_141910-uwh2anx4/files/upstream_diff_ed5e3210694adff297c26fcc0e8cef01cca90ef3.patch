diff --git a/hazGAN/WGAN.py b/hazGAN/WGAN.py
index cc142e5..e5ce589 100644
--- a/hazGAN/WGAN.py
+++ b/hazGAN/WGAN.py
@@ -12,6 +12,7 @@ from tensorflow.keras import optimizers
 from tensorflow.keras import layers
 from inspect import signature
 from .extreme_value_theory import chi_loss, inv_gumbel
+from .augment import DiffAugment
 
 
 def sample_gumbel(shape, eps=1e-20, temperature=1., offset=0., seed=None):
@@ -146,6 +147,7 @@ class WGAN(keras.Model):
             self.inv = inv_gumbel
         else:
             self.inv = lambda x: x
+        self.augment = lambda x: DiffAugment(x, config.augment_policy)
 
         # trackers average over batches
         self.chi_rmse_tracker = keras.metrics.Mean(name="chi_rmse")
@@ -187,8 +189,8 @@ class WGAN(keras.Model):
         # https://github.com/igul222/improved_wgan_training/blob/master/gan_mnist.py:134
         for _ in range(self.config.training_balance):
             with tf.GradientTape() as tape:
-                score_real = self.critic(data)
-                score_fake = self.critic(fake_data)
+                score_real = self.critic(self.augment(data))
+                score_fake = self.critic(self.augment(fake_data))
                 critic_loss = tf.reduce_mean(score_fake) - tf.reduce_mean(score_real) # value function (observed to correlate with sample quality --Gulrajani 2017)
                 eps = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)
                 differences = fake_data - data
@@ -209,7 +211,7 @@ class WGAN(keras.Model):
         random_latent_vectors = self.latent_space_distn((batch_size, self.latent_dim))
         with tf.GradientTape() as tape:
             generated_data = self.generator(random_latent_vectors)
-            score = self.critic(generated_data, training=False)
+            score = self.critic(self.augment(generated_data), training=False)
             generator_loss_raw = -tf.reduce_mean(score)
             chi_rmse = chi_loss(self.inv(data), self.inv(generated_data)) # think this is safe inside GradientTape
             if self.lambda_chi > 0: # NOTE: this doesn't work with GPU
diff --git a/hazGAN/augment.py b/hazGAN/augment.py
new file mode 100644
index 0000000..e15d517
--- /dev/null
+++ b/hazGAN/augment.py
@@ -0,0 +1,122 @@
+"""
+Differentiable Augmentation for Data-Efficient GAN Training
+Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han
+https://arxiv.org/pdf/2006.10738
+https://github.com/mit-han-lab/data-efficient-gans
+
+Example:
+---------
+>>> from DiffAugment_pytorch import DiffAugment
+>>> policy = 'color,translation,cutout'
+
+>>> # Training loop: update D
+>>> reals = sample_real_images() # a batch of real images
+>>> z = sample_latent_vectors()
+>>> fakes = Generator(z) # a batch of fake images
+>>> real_scores = Discriminator(DiffAugment(reals, policy=policy))
+>>> fake_scores = Discriminator(DiffAugment(fakes, policy=policy))
+>>> # Calculating D's loss based on real_scores and fake_scores...
+
+>>> # Training loop: update G
+>>> z = sample_latent_vectors()
+>>> fakes = Generator(z) # a batch of fake images
+>>> fake_scores = Discriminator(DiffAugment(fakes, policy=policy))
+>>> # Calculating G's loss based on fake_scores...
+...
+
+----------------- License -----------------
+Copyright (c) 2020, Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright notice,
+  this list of conditions and the following disclaimer in the documentation
+  and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+"""
+# %%
+import tensorflow as tf
+
+
+def DiffAugment(x, policy='', channels_first=False):
+    if policy:
+        if channels_first:
+            x = tf.transpose(x, [0, 2, 3, 1])
+        for p in policy.split(','):
+            for f in AUGMENT_FNS[p]:
+                x = f(x)
+        if channels_first:
+            x = tf.transpose(x, [0, 3, 1, 2])
+    return x
+
+
+def rand_brightness(x):
+    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) - 0.5
+    x = x + magnitude
+    return x
+
+
+def rand_saturation(x):
+    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) * 2
+    x_mean = tf.reduce_mean(x, axis=3, keepdims=True)
+    x = (x - x_mean) * magnitude + x_mean
+    return x
+
+
+def rand_contrast(x):
+    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) + 0.5
+    x_mean = tf.reduce_mean(x, axis=[1, 2, 3], keepdims=True)
+    x = (x - x_mean) * magnitude + x_mean
+    return x
+
+
+def rand_translation(x, ratio=0.125):
+    batch_size = tf.shape(x)[0]
+    image_size = tf.shape(x)[1:3]
+    shift = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)
+    translation_x = tf.random.uniform([batch_size, 1], -shift[0], shift[0] + 1, dtype=tf.int32)
+    translation_y = tf.random.uniform([batch_size, 1], -shift[1], shift[1] + 1, dtype=tf.int32)
+    grid_x = tf.clip_by_value(tf.expand_dims(tf.range(image_size[0], dtype=tf.int32), 0) + translation_x + 1, 0, image_size[0] + 1)
+    grid_y = tf.clip_by_value(tf.expand_dims(tf.range(image_size[1], dtype=tf.int32), 0) + translation_y + 1, 0, image_size[1] + 1)
+    x = tf.gather_nd(tf.pad(x, [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_x, -1), batch_dims=1)
+    x = tf.transpose(tf.gather_nd(tf.pad(tf.transpose(x, [0, 2, 1, 3]), [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_y, -1), batch_dims=1), [0, 2, 1, 3])
+    return x
+
+
+def rand_cutout(x, ratio=0.5):
+    batch_size = tf.shape(x)[0]
+    image_size = tf.shape(x)[1:3]
+    cutout_size = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)
+    offset_x = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[0] + (1 - cutout_size[0] % 2), dtype=tf.int32)
+    offset_y = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[1] + (1 - cutout_size[1] % 2), dtype=tf.int32)
+    grid_batch, grid_x, grid_y = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(cutout_size[0], dtype=tf.int32), tf.range(cutout_size[1], dtype=tf.int32), indexing='ij')
+    cutout_grid = tf.stack([grid_batch, grid_x + offset_x - cutout_size[0] // 2, grid_y + offset_y - cutout_size[1] // 2], axis=-1)
+    mask_shape = tf.stack([batch_size, image_size[0], image_size[1]])
+    cutout_grid = tf.maximum(cutout_grid, 0)
+    cutout_grid = tf.minimum(cutout_grid, tf.reshape(mask_shape - 1, [1, 1, 1, 3]))
+    mask = tf.maximum(1 - tf.scatter_nd(cutout_grid, tf.ones([batch_size, cutout_size[0], cutout_size[1]], dtype=tf.float32), mask_shape), 0)
+    x = x * tf.expand_dims(mask, axis=3)
+    return x
+
+
+AUGMENT_FNS = {
+    'color': [rand_brightness, rand_saturation, rand_contrast],
+    'translation': [rand_translation],
+    'cutout': [rand_cutout],
+}
+# %%
\ No newline at end of file
diff --git a/hazGAN/callbacks.py b/hazGAN/callbacks.py
index 22651d7..57d882d 100644
--- a/hazGAN/callbacks.py
+++ b/hazGAN/callbacks.py
@@ -16,6 +16,37 @@ class WandbMetricsLogger(Callback):
         wandb.log(logs)
 
 
+class CountImagesSeen(Callback):
+    def __init__(self):
+        super().__init__()
+        self.images_seen = 0
+
+    def on_train_batch_begin(self, batch, logs=None):
+        pass  # We'll count at the end of the batch instead
+
+    def on_train_batch_end(self, batch, logs=None):
+        if logs is None:
+            logs = {}
+        
+        # Access the actual batch data
+        if hasattr(self.model, 'train_function'):
+            inputs = self.model.train_function.inputs
+            if inputs:
+                batch_size = tf.shape(inputs[0])[0].numpy()
+                self.images_seen += int(batch_size)
+                print(f"Batch {batch} end. Batch size: {batch_size}, Total images seen: {self.images_seen}")
+            else:
+                print(f"Batch {batch} end. Unable to determine batch size.")
+        else:
+            print(f"Batch {batch} end. Model train function not available.")
+
+    def on_epoch_end(self, epoch, logs=None):
+        if logs is None:
+            logs = {}
+        print(f"Epoch {epoch + 1} ended. Total images seen: {self.images_seen}")
+        wandb.log({"images_seen": self.images_seen, "epoch": epoch + 1})
+
+
 class Visualiser(Callback):
     def __init__(self, frequency=1, runname='untitled'):
         super().__init__()
@@ -62,7 +93,7 @@ class CriticVal(Callback):
             nbatch = 0
             score = 0
             for batch in self.validation_data:
-                score += self.model.critic(batch, training=False)
+                score += self.model.critic(self.model.augment(batch), training=False)
                 nbatch += 1
             score = score / nbatch
             logs["critic_val"] = tf.reduce_mean(score).numpy()
diff --git a/scripts/training/config-defaults.yaml b/scripts/training/config-defaults.yaml
index 680d4c9..8d2e199 100644
--- a/scripts/training/config-defaults.yaml
+++ b/scripts/training/config-defaults.yaml
@@ -4,7 +4,7 @@ model:
   value: wgan
 nepochs:
   desc: Gulrajani et al. 2017 use 200_000
-  value: 5000 # 3000 # or 1,500,000/train_size
+  value: 10 # 3000 # or 1,500,000/train_size
 train_size:
   value: 128 # 840 # 50
 batch_size:
@@ -14,7 +14,10 @@ chi_frequency:
   value: 1
 u10_min:
   desc: Minimum value of u10 anomaly for training data
-  value: -999 # you get two footprints if 40, 6 for 32.5 [15, 32.5, 40]
+  value: 15 # you get two footprints if 40, 6 for 32.5 [15, 32.5, 40]
+augment_policy:
+  desc: Subset of 'color,translation,cutout' or ''
+  value: 'color,translation,cutout'
 
 # training features
 optimizer:
diff --git a/scripts/training/train.py b/scripts/training/train.py
index 453a500..78d2f4f 100644
--- a/scripts/training/train.py
+++ b/scripts/training/train.py
@@ -135,6 +135,8 @@ def main(config):
         )
     
     critic_val = hg.CriticVal(test, frequency=config.chi_frequency)
+
+    images_seen = hg.CountImagesSeen()
     
     compound = hg.CompoundMetric(frequency=config.chi_frequency)
 
@@ -164,7 +166,8 @@ def main(config):
             epochs=config.nepochs,
             callbacks=[
                 # early_stopping,
-                critic_val,
+                # critic_val,
+                images_seen,
                 chi_score,
                 chi_squared,
                 compound,
@@ -329,9 +332,9 @@ if __name__ == "__main__":
         print("Starting dry run")
         wandb.init(project="test", mode="disabled")
         wandb.config.update({
-            'nepochs': 1,
-            'train_size': 3,
-            'batch_size': 2,
+            'nepochs': 128,
+            'train_size': 128,
+            'batch_size': 128,
             'chi_frequency': 1
             },
             allow_val_change=True)
